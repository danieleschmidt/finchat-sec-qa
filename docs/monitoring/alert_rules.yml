# Prometheus Alert Rules for FinChat-SEC-QA
# Configure these rules in your Prometheus instance

groups:
  - name: finchat-critical
    rules:
      # Service availability alerts
      - alert: ServiceDown
        expr: up{job="finchat-api"} == 0
        for: 1m
        labels:
          severity: critical
          service: finchat-api
        annotations:
          summary: "FinChat API service is down"
          description: "The FinChat API service has been down for more than 1 minute."
          runbook_url: "https://docs.company.com/runbooks/incident_response"

      - alert: HighErrorRate
        expr: |
          (
            sum(rate(http_requests_total{job="finchat-api",code=~"5.."}[5m])) /
            sum(rate(http_requests_total{job="finchat-api"}[5m]))
          ) > 0.05
        for: 2m
        labels:
          severity: critical
          service: finchat-api
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} over the last 5 minutes."
          runbook_url: "https://docs.company.com/runbooks/performance_monitoring"

      - alert: HighResponseTime
        expr: |
          histogram_quantile(0.95,
            sum(rate(http_request_duration_seconds_bucket{job="finchat-api"}[5m])) by (le)
          ) > 10
        for: 5m
        labels:
          severity: critical
          service: finchat-api
        annotations:
          summary: "High response time detected"
          description: "95th percentile response time is {{ $value }}s over the last 5 minutes."
          runbook_url: "https://docs.company.com/runbooks/performance_monitoring"

  - name: finchat-warning
    rules:
      # Resource utilization alerts
      - alert: HighCPUUsage
        expr: |
          100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 10m
        labels:
          severity: warning
          service: system
        annotations:
          summary: "High CPU usage detected"
          description: "CPU usage is {{ $value }}% on {{ $labels.instance }}."
          runbook_url: "https://docs.company.com/runbooks/performance_monitoring"

      - alert: HighMemoryUsage
        expr: |
          (
            (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) /
            node_memory_MemTotal_bytes
          ) > 0.85
        for: 10m
        labels:
          severity: warning
          service: system
        annotations:
          summary: "High memory usage detected"
          description: "Memory usage is {{ $value | humanizePercentage }} on {{ $labels.instance }}."
          runbook_url: "https://docs.company.com/runbooks/performance_monitoring"

      - alert: LowDiskSpace
        expr: |
          (
            (node_filesystem_size_bytes{fstype!="tmpfs"} - node_filesystem_free_bytes{fstype!="tmpfs"}) /
            node_filesystem_size_bytes{fstype!="tmpfs"}
          ) > 0.85
        for: 5m
        labels:
          severity: warning
          service: system
        annotations:
          summary: "Low disk space detected"
          description: "Disk usage is {{ $value | humanizePercentage }} on {{ $labels.instance }}:{{ $labels.mountpoint }}."
          runbook_url: "https://docs.company.com/runbooks/operational_procedures"

      # Application-specific alerts
      - alert: LowCacheHitRate
        expr: |
          (
            sum(rate(finchat_cache_hits_total[10m])) /
            sum(rate(finchat_cache_requests_total[10m]))
          ) < 0.7
        for: 15m
        labels:
          severity: warning
          service: finchat-cache
        annotations:
          summary: "Low cache hit rate detected"
          description: "Cache hit rate is {{ $value | humanizePercentage }} over the last 10 minutes."
          runbook_url: "https://docs.company.com/runbooks/performance_monitoring"

      - alert: EDGARAPILatency
        expr: |
          histogram_quantile(0.95,
            sum(rate(finchat_edgar_request_duration_seconds_bucket[5m])) by (le)
          ) > 30
        for: 5m
        labels:
          severity: warning
          service: edgar-api
        annotations:
          summary: "High EDGAR API latency detected"
          description: "95th percentile EDGAR API response time is {{ $value }}s."
          runbook_url: "https://docs.company.com/runbooks/performance_monitoring"

      - alert: HighQueryLatency
        expr: |
          histogram_quantile(0.95,
            sum(rate(finchat_query_duration_seconds_bucket[5m])) by (le)
          ) > 5
        for: 10m
        labels:
          severity: warning
          service: finchat-queries
        annotations:
          summary: "High query processing latency"
          description: "95th percentile query processing time is {{ $value }}s."
          runbook_url: "https://docs.company.com/runbooks/performance_monitoring"

  - name: finchat-security
    rules:
      # Security-related alerts
      - alert: HighFailedAuthAttempts
        expr: |
          sum(rate(finchat_auth_failures_total[5m])) > 10
        for: 2m
        labels:
          severity: warning
          service: finchat-auth
        annotations:
          summary: "High number of authentication failures"
          description: "{{ $value }} authentication failures per second over the last 5 minutes."
          runbook_url: "https://docs.company.com/runbooks/incident_response"

      - alert: SuspiciousActivity
        expr: |
          sum(rate(finchat_suspicious_requests_total[5m])) > 5
        for: 1m
        labels:
          severity: critical
          service: finchat-security
        annotations:
          summary: "Suspicious activity detected"
          description: "{{ $value }} suspicious requests per second detected."
          runbook_url: "https://docs.company.com/runbooks/incident_response"

      - alert: RateLimitExceeded
        expr: |
          sum(rate(finchat_rate_limit_exceeded_total[5m])) > 20
        for: 5m
        labels:
          severity: warning
          service: finchat-ratelimit
        annotations:
          summary: "Rate limit frequently exceeded"
          description: "Rate limit exceeded {{ $value }} times per second over the last 5 minutes."
          runbook_url: "https://docs.company.com/runbooks/performance_monitoring"

  - name: finchat-business
    rules:
      # Business metric alerts
      - alert: LowQueryVolume
        expr: |
          sum(rate(finchat_queries_total[1h])) < 10
        for: 30m
        labels:
          severity: info
          service: finchat-business
        annotations:
          summary: "Unusually low query volume"
          description: "Query rate is {{ $value }} per second over the last hour."
          runbook_url: "https://docs.company.com/runbooks/operational_procedures"

      - alert: HighQueryVolume
        expr: |
          sum(rate(finchat_queries_total[5m])) > 100
        for: 10m
        labels:
          severity: warning
          service: finchat-business
        annotations:
          summary: "Unusually high query volume"
          description: "Query rate is {{ $value }} per second, consider scaling."
          runbook_url: "https://docs.company.com/runbooks/performance_monitoring"

      - alert: DataFreshnessIssue
        expr: |
          time() - finchat_last_edgar_update_timestamp > 86400
        for: 1h
        labels:
          severity: warning
          service: finchat-data
        annotations:
          summary: "EDGAR data not updated recently"
          description: "Last EDGAR data update was {{ $value | humanizeDuration }} ago."
          runbook_url: "https://docs.company.com/runbooks/operational_procedures"

# Alert notification configuration
# Configure in Alertmanager
# 
# Example Alertmanager configuration:
# 
# route:
#   group_by: ['alertname', 'service']
#   group_wait: 10s
#   group_interval: 10s
#   repeat_interval: 1h
#   receiver: 'default'
#   routes:
#   - match:
#       severity: critical
#     receiver: 'critical-alerts'
#   - match:
#       severity: warning
#     receiver: 'warning-alerts'
# 
# receivers:
# - name: 'default'
#   slack_configs:
#   - api_url: 'YOUR_SLACK_WEBHOOK_URL'
#     channel: '#alerts'
#     title: 'FinChat Alert'
#     text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
# 
# - name: 'critical-alerts'
#   pagerduty_configs:
#   - routing_key: 'YOUR_PAGERDUTY_KEY'
#     description: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
#   slack_configs:
#   - api_url: 'YOUR_SLACK_WEBHOOK_URL'
#     channel: '#critical-alerts'
#     title: 'üö® CRITICAL: FinChat Alert'
#     text: '{{ range .Alerts }}{{ .Annotations.summary }}\n{{ .Annotations.description }}{{ end }}'
# 
# - name: 'warning-alerts'
#   slack_configs:
#   - api_url: 'YOUR_SLACK_WEBHOOK_URL'
#     channel: '#alerts'
#     title: '‚ö†Ô∏è WARNING: FinChat Alert'
#     text: '{{ range .Alerts }}{{ .Annotations.summary }}\n{{ .Annotations.description }}{{ end }}'